# Copyright (c) 2021-2025, ETH Zurich and NVIDIA CORPORATION
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

"""
ActorCriticElevationNetMode2: ç‰¹å¾æå–+èåˆæ¶æ„

ç½‘ç»œç»“æ„:
    æœ¬ä½“ -> æœ¬ä½“ç¼–ç å™¨MLP -> ç‰¹å¾1
    é«˜ç¨‹å›¾ -> é«˜ç¨‹å›¾ç¼–ç å™¨MLP -> ç‰¹å¾2
    [ç‰¹å¾1 + ç‰¹å¾2] -> èåˆMLP -> åŠ¨ä½œ
"""

from __future__ import annotations

import torch
import torch.nn as nn
from tensordict import TensorDict
from torch.distributions import Normal
from typing import Any, NoReturn

from rsl_rl.networks import MLP, EmpiricalNormalization


class ActorCriticElevationNetMode2(nn.Module):
    """Mode2: æœ¬ä½“å’Œé«˜ç¨‹å›¾åˆ†åˆ«æå–ç‰¹å¾åèåˆè¾“å‡ºåŠ¨ä½œ
    
    å››ä¸ªMLPç½‘ç»œ:
    1. æœ¬ä½“ç¼–ç å™¨MLP - æå–æœ¬ä½“ç‰¹å¾
    2. é«˜ç¨‹å›¾ç¼–ç å™¨MLP - æå–è§†è§‰ç‰¹å¾
    3. ActorèåˆMLP - èåˆç‰¹å¾åè¾“å‡ºåŠ¨ä½œ
    4. Critic MLP - ä»·å€¼è¯„ä¼°
    """
    
    is_recurrent: bool = False

    def __init__(
        self,
        obs: TensorDict,
        obs_groups: dict[str, list[str]],
        num_actions: int,
        actor_obs_normalization: bool = False,
        critic_obs_normalization: bool = False,
        actor_hidden_dims: tuple[int] | list[int] = [256, 128],
        critic_hidden_dims: tuple[int] | list[int] = [512, 256, 128],
        activation: str = "elu",
        init_noise_std: float = 1.0,
        noise_std_type: str = "scalar",
        # é«˜ç¨‹å›¾ç¼–ç å™¨é…ç½®
        vision_feature_dim: int = 64,
        vision_num_frames: int = 1,
        vision_spatial_size: tuple[int, int] = (25, 17),
        elevation_encoder_hidden_dims: list[int] | None = None,
        # æœ¬ä½“ç¼–ç å™¨é…ç½®
        proprio_feature_dim: int = 64,
        proprio_encoder_hidden_dims: list[int] | None = None,
        # èåˆç½‘ç»œé…ç½®
        fusion_actor_hidden_dims: list[int] | None = None,
        **kwargs: dict[str, Any],
    ) -> None:
        super().__init__()

        # é…ç½®
        self.cfg = kwargs
        self.extra_info = dict()
        self.obs_groups = obs_groups
        self.vision_spatial_size = vision_spatial_size
        self.noise_std_type = noise_std_type
        
        # è®¡ç®—è§‚æµ‹ç»´åº¦
        num_actor_obs = sum(obs[g].shape[-1] for g in obs_groups["policy"] if g != "height_scan_history")
        num_critic_obs = sum(obs[g].shape[-1] for g in obs_groups["critic"] if g != "height_scan_history")
        
        # è®¡ç®—é«˜ç¨‹å›¾å±•å¹³åçš„ç»´åº¦
        height, width = vision_spatial_size
        height_map_dim = height * width
        height_map_input_dim = vision_num_frames * height_map_dim
        
        ########################################## Actor ##############################################
        print("\n" + "=" * 80)
        print("ğŸŒŸ ç½‘ç»œæ¶æ„: ElevationNet Mode2")
        print("=" * 80)
        print("âœ“ Mode2: æœ¬ä½“ç¼–ç å™¨ + é«˜ç¨‹å›¾ç¼–ç å™¨ + èåˆç½‘ç»œ -> åŠ¨ä½œ")
        
        # 1. æœ¬ä½“ç¼–ç å™¨MLP
        if proprio_encoder_hidden_dims is None:
            proprio_encoder_hidden_dims = actor_hidden_dims
        self.proprio_encoder = MLP(num_actor_obs, proprio_feature_dim, proprio_encoder_hidden_dims, activation)
        print(f"  1. æœ¬ä½“ç¼–ç å™¨: {num_actor_obs} -> {proprio_encoder_hidden_dims} -> {proprio_feature_dim}")
        
        # 2. é«˜ç¨‹å›¾ç¼–ç å™¨MLP
        if elevation_encoder_hidden_dims is None:
            elevation_encoder_hidden_dims = [max(height_map_input_dim // 2, vision_feature_dim * 2), vision_feature_dim * 2]
        self.elevation_net = MLP(height_map_input_dim, vision_feature_dim, elevation_encoder_hidden_dims, "elu")
        print(f"  2. é«˜ç¨‹å›¾ç¼–ç å™¨: {height_map_input_dim} ({vision_num_frames}Ã—{height_map_dim}) -> {elevation_encoder_hidden_dims} -> {vision_feature_dim}")
        
        # 3. ActorèåˆMLP
        if fusion_actor_hidden_dims is None:
            fusion_actor_hidden_dims = actor_hidden_dims if actor_hidden_dims else [256, 128]
            print(f"     â„¹ï¸  fusion_actor_hidden_dimsæœªè®¾ç½®ï¼Œä½¿ç”¨actor_hidden_dims={fusion_actor_hidden_dims}")
        fusion_input_dim = proprio_feature_dim + vision_feature_dim
        self.fusion_actor = MLP(fusion_input_dim, num_actions, fusion_actor_hidden_dims, "elu")
        print(f"  3. èåˆMLP: {fusion_input_dim} (æœ¬ä½“{proprio_feature_dim} + è§†è§‰{vision_feature_dim}) -> {fusion_actor_hidden_dims} -> {num_actions}")

        # Actor observation normalization
        self.actor_obs_normalization = actor_obs_normalization
        if actor_obs_normalization:
            self.actor_obs_normalizer = EmpiricalNormalization(num_actor_obs)
        else:
            self.actor_obs_normalizer = torch.nn.Identity()

        ########################################## Critic ##############################################
        self.critic = MLP(num_critic_obs, 1, critic_hidden_dims, activation)
        print(f"  4. Critic MLP: {num_critic_obs} -> {critic_hidden_dims} -> 1")
        print("=" * 80 + "\n")

        # Critic observation normalization
        self.critic_obs_normalization = critic_obs_normalization
        if critic_obs_normalization:
            self.critic_obs_normalizer = EmpiricalNormalization(num_critic_obs)
        else:
            self.critic_obs_normalizer = torch.nn.Identity()

        ########################################## Action Noise ##############################################
        if self.noise_std_type == "scalar":
            self.std = nn.Parameter(init_noise_std * torch.ones(num_actions))
        elif self.noise_std_type == "log":
            self.log_std = nn.Parameter(torch.log(init_noise_std * torch.ones(num_actions)))
        else:
            raise ValueError(f"Unknown standard deviation type: {self.noise_std_type}")

        # Action distribution
        self.distribution = None
        Normal.set_default_validate_args(False)

    def reset(self, dones: torch.Tensor | None = None) -> None:
        pass

    def forward(self) -> NoReturn:
        raise NotImplementedError

    @property
    def action_mean(self) -> torch.Tensor:
        return self.distribution.mean

    @property
    def action_std(self) -> torch.Tensor:
        return self.distribution.stddev

    @property
    def entropy(self) -> torch.Tensor:
        return self.distribution.entropy().sum(dim=-1)

    def _extract_height_map_sequence(self, obs: TensorDict) -> torch.Tensor:
        """æå–é«˜ç¨‹å›¾åºåˆ—å¹¶å±•å¹³"""
        depth_obs = obs["height_scan_history"]
        while isinstance(depth_obs, TensorDict):
            keys = list(depth_obs.keys())
            depth_obs = depth_obs[keys[0]]
        # å±•å¹³æ‰€æœ‰å¸§: [batch, frames, height*width] -> [batch, frames*height*width]
        batch_size = depth_obs.shape[0]
        return depth_obs.view(batch_size, -1)

    def _update_distribution(self, mean: torch.Tensor) -> None:
        """æ›´æ–°åŠ¨ä½œåˆ†å¸ƒ"""
        if self.noise_std_type == "scalar":
            std = self.std.expand_as(mean)
        elif self.noise_std_type == "log":
            std = torch.exp(self.log_std).expand_as(mean)
        
        self.distribution = Normal(mean, std)

    def act(self, obs: TensorDict, **kwargs: dict[str, Any]) -> tuple[torch.Tensor, dict]:
        """è®­ç»ƒæ—¶çš„åŠ¨ä½œé‡‡æ ·"""
        # 1. è·å–å¹¶å½’ä¸€åŒ–æœ¬ä½“è§‚æµ‹
        proprio_obs = self.get_actor_obs(obs)
        proprio_obs = self.actor_obs_normalizer(proprio_obs)
        
        # 2. æå–æœ¬ä½“ç‰¹å¾
        proprio_features = self.proprio_encoder(proprio_obs)
        
        # 3. æå–é«˜ç¨‹å›¾ç‰¹å¾
        height_map_sequence = self._extract_height_map_sequence(obs)
        vision_features = self.elevation_net(height_map_sequence)
        
        # 4. èåˆç‰¹å¾å¹¶è¾“å‡ºåŠ¨ä½œ
        fused_features = torch.cat([proprio_features, vision_features], dim=-1)
        mean = self.fusion_actor(fused_features)
        
        self._update_distribution(mean)
        return self.distribution.sample(), self.extra_info

    def act_inference(self, obs: TensorDict) -> tuple[torch.Tensor, dict]:
        """æ¨ç†æ—¶çš„ç¡®å®šæ€§åŠ¨ä½œ"""
        # 1. è·å–å¹¶å½’ä¸€åŒ–æœ¬ä½“è§‚æµ‹
        proprio_obs = self.get_actor_obs(obs)
        proprio_obs = self.actor_obs_normalizer(proprio_obs)
        
        # 2. æå–æœ¬ä½“ç‰¹å¾
        proprio_features = self.proprio_encoder(proprio_obs)
        
        # 3. æå–é«˜ç¨‹å›¾ç‰¹å¾
        height_map_sequence = self._extract_height_map_sequence(obs)
        vision_features = self.elevation_net(height_map_sequence)
        
        # 4. èåˆç‰¹å¾å¹¶è¾“å‡ºåŠ¨ä½œï¼ˆç¡®å®šæ€§ï¼‰
        fused_features = torch.cat([proprio_features, vision_features], dim=-1)
        mean = self.fusion_actor(fused_features)
        
        return mean, self.extra_info

    def evaluate(self, obs: TensorDict, **kwargs: dict[str, Any]) -> torch.Tensor:
        """è¯„ä¼°çŠ¶æ€ä»·å€¼"""
        obs = self.get_critic_obs(obs)
        obs = self.critic_obs_normalizer(obs)
        return self.critic(obs)

    def get_actor_obs(self, obs: TensorDict) -> torch.Tensor:
        """è·å–actorçš„æœ¬ä½“è§‚æµ‹(æ’é™¤é«˜ç¨‹å›¾)"""
        obs_list = []
        for obs_group in self.obs_groups["policy"]:
            if obs_group != "height_scan_history":
                obs_list.append(obs[obs_group])
        return torch.cat(obs_list, dim=-1) if obs_list else torch.empty(obs[self.obs_groups["policy"][0]].shape[0], 0)

    def get_critic_obs(self, obs: TensorDict) -> torch.Tensor:
        """è·å–criticè§‚æµ‹(æ’é™¤é«˜ç¨‹å›¾)"""
        obs_list = []
        for obs_group in self.obs_groups["critic"]:
            if obs_group != "height_scan_history":
                obs_list.append(obs[obs_group])
        return torch.cat(obs_list, dim=-1) if obs_list else torch.empty(obs[self.obs_groups["critic"][0]].shape[0], 0)

    def get_actions_log_prob(self, actions: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—åŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡"""
        return self.distribution.log_prob(actions).sum(dim=-1)

    def update_normalization(self, obs: TensorDict) -> None:
        """æ›´æ–°è§‚æµ‹å½’ä¸€åŒ–ç»Ÿè®¡é‡"""
        if self.actor_obs_normalization:
            actor_obs = self.get_actor_obs(obs)
            self.actor_obs_normalizer.update(actor_obs)
        if self.critic_obs_normalization:
            critic_obs = self.get_critic_obs(obs)
            self.critic_obs_normalizer.update(critic_obs)

    def load_state_dict(self, state_dict: dict, strict: bool = True) -> bool:
        """åŠ è½½æ¨¡å‹å‚æ•°"""
        super().load_state_dict(state_dict, strict=strict)
        return True
