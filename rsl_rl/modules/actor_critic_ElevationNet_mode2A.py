# Copyright (c) 2021-2025, ETH Zurich and NVIDIA CORPORATION
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

"""
ActorCriticElevationNetMode2A: ç®€åŒ–èåˆæ¶æ„

ç½‘ç»œç»“æ„:
    æœ¬ä½“è§‚æµ‹ -> ç›´æ¥è¿›å…¥èåˆå±‚
    é«˜ç¨‹å›¾ -> é«˜ç¨‹å›¾ç¼–ç å™¨MLP -> ç‰¹å¾ -> èåˆå±‚
    [æœ¬ä½“è§‚æµ‹ + ç‰¹å¾] -> èåˆMLP -> åŠ¨ä½œ

ä¸Mode2çš„åŒºåˆ«:
- å»æ‰æœ¬ä½“è§‚æµ‹çš„ç‰¹å¾æå–ç½‘ç»œ
- æœ¬ä½“è§‚æµ‹å€¼ç›´æ¥è¿›å…¥fusionå±‚
- é«˜ç¨‹å›¾å…ˆè¿›MLPæå–ç‰¹å¾å†è¿›fusionå±‚
"""

from __future__ import annotations

import torch
import torch.nn as nn
from tensordict import TensorDict
from torch.distributions import Normal
from typing import Any, NoReturn

from rsl_rl.networks import MLP, EmpiricalNormalization
import copy
import os

class ActorCriticElevationNetMode2A(nn.Module):
    """Mode2A: æœ¬ä½“è§‚æµ‹ç›´æ¥èåˆï¼Œé«˜ç¨‹å›¾ç‰¹å¾æå–åèåˆ
    
    ä¸‰ä¸ªMLPç½‘ç»œ:
    1. é«˜ç¨‹å›¾ç¼–ç å™¨MLP - æå–è§†è§‰ç‰¹å¾
    2. ActorèåˆMLP - èåˆæœ¬ä½“è§‚æµ‹å’Œè§†è§‰ç‰¹å¾åè¾“å‡ºåŠ¨ä½œ
    3. Critic MLP - ä»·å€¼è¯„ä¼°
    """
    
    is_recurrent: bool = False

    def __init__(
        self,
        obs: TensorDict,
        obs_groups: dict[str, list[str]],
        num_actions: int,
        env_cfg=None,
        alg_cfg: dict | None = None,
        actor_obs_normalization: bool = False,
        critic_obs_normalization: bool = False,
        actor_hidden_dims: tuple[int] | list[int] = [256, 128],
        critic_hidden_dims: tuple[int] | list[int] = [512, 256, 128],
        activation: str = "elu",
        init_noise_std: float = 1.0,
        noise_std_type: str = "scalar",
        # é«˜ç¨‹å›¾ç¼–ç å™¨é…ç½®
        vision_feature_dim: int = 64,
        vision_num_frames: int = 1,
        vision_spatial_size: tuple[int, int] = (25, 17),
        elevation_encoder_hidden_dims: list[int] | None = None,
        # èåˆç½‘ç»œé…ç½®
        fusion_actor_hidden_dims: list[int] | None = None,
        **kwargs: dict[str, Any],
    ) -> None:
        super().__init__()

        # é…ç½®
        self.cfg = kwargs
        self.extra_info = dict()
        self.obs_groups = obs_groups
        self.vision_spatial_size = vision_spatial_size
        self.noise_std_type = noise_std_type
        
        # è®¡ç®—è§‚æµ‹ç»´åº¦
        num_actor_obs = sum(obs[g].shape[-1] for g in obs_groups["policy"] if g != "height_scan_history")
        num_critic_obs = sum(obs[g].shape[-1] for g in obs_groups["critic"] if g != "height_scan_history")
        
        # è®¡ç®—é«˜ç¨‹å›¾å±•å¹³åçš„ç»´åº¦
        height, width = vision_spatial_size
        height_map_dim = height * width
        height_map_input_dim = vision_num_frames * height_map_dim
        
        ########################################## Actor ##############################################
        print("\n" + "=" * 80)
        print("ğŸŒŸ ç½‘ç»œæ¶æ„: ElevationNet Mode2A")
        print("=" * 80)
        print("âœ“ Mode2A: æœ¬ä½“è§‚æµ‹ç›´æ¥èåˆ + é«˜ç¨‹å›¾ç¼–ç å™¨ + èåˆç½‘ç»œ -> åŠ¨ä½œ")
        
        # 1. é«˜ç¨‹å›¾ç¼–ç å™¨MLP
        self.elevation_net = MLP(height_map_input_dim, vision_feature_dim, elevation_encoder_hidden_dims, "elu")
        print(f"  1. é«˜ç¨‹å›¾ç¼–ç å™¨: {height_map_input_dim} ({vision_num_frames}Ã—{height_map_dim}) -> {elevation_encoder_hidden_dims} -> {vision_feature_dim}")
        
        # 2. ActorèåˆMLP
        fusion_input_dim = num_actor_obs + vision_feature_dim
        self.fusion_actor = MLP(fusion_input_dim, num_actions, fusion_actor_hidden_dims, "elu")
        print(f"  2. èåˆMLP: {fusion_input_dim} (æœ¬ä½“è§‚æµ‹{num_actor_obs} + è§†è§‰ç‰¹å¾{vision_feature_dim}) -> {fusion_actor_hidden_dims} -> {num_actions}")

        # Actor observation normalization
        self.actor_obs_normalization = actor_obs_normalization
        if actor_obs_normalization:
            self.actor_obs_normalizer = EmpiricalNormalization(num_actor_obs)
        else:
            self.actor_obs_normalizer = torch.nn.Identity()

        ########################################## Critic ##############################################
        self.critic = MLP(num_critic_obs, 1, critic_hidden_dims, activation)
        print(f"  3. Critic MLP: {num_critic_obs} -> {critic_hidden_dims} -> 1")
        print("=" * 80 + "\n")

        # Critic observation normalization
        self.critic_obs_normalization = critic_obs_normalization
        if critic_obs_normalization:
            self.critic_obs_normalizer = EmpiricalNormalization(num_critic_obs)
        else:
            self.critic_obs_normalizer = torch.nn.Identity()

        ########################################## Action Noise ##############################################
        if self.noise_std_type == "scalar":
            self.std = nn.Parameter(init_noise_std * torch.ones(num_actions))
        elif self.noise_std_type == "log":
            self.log_std = nn.Parameter(torch.log(init_noise_std * torch.ones(num_actions)))
        else:
            raise ValueError(f"Unknown standard deviation type: {self.noise_std_type}")

        # Action distribution
        self.distribution = None
        Normal.set_default_validate_args(False)

    def reset(self, dones: torch.Tensor | None = None) -> None:
        pass

    def forward(self) -> NoReturn:
        raise NotImplementedError

    @property
    def action_mean(self) -> torch.Tensor:
        return self.distribution.mean

    @property
    def action_std(self) -> torch.Tensor:
        return self.distribution.stddev

    @property
    def entropy(self) -> torch.Tensor:
        return self.distribution.entropy().sum(dim=-1)

    # def _extract_height_map_sequence(self, obs: TensorDict) -> torch.Tensor:
    #     """æå–é«˜ç¨‹å›¾åºåˆ—å¹¶å±•å¹³"""
    #     depth_obs = obs["height_scan_history"]
    #     while isinstance(depth_obs, TensorDict):
    #         keys = list(depth_obs.keys())
    #         depth_obs = depth_obs[keys[0]]
    #     # å±•å¹³æ‰€æœ‰å¸§: [batch, frames, height*width] -> [batch, frames*height*width]
    #     batch_size = depth_obs.shape[0]
    #     return depth_obs.view(batch_size, -1)

    def _update_distribution(self, mean: torch.Tensor) -> None:
        """æ›´æ–°åŠ¨ä½œåˆ†å¸ƒ"""
        if self.noise_std_type == "scalar":
            std = self.std.expand_as(mean)
        elif self.noise_std_type == "log":
            std = torch.exp(self.log_std).expand_as(mean)
        
        self.distribution = Normal(mean, std)

    def act(self, obs: TensorDict, **kwargs: dict[str, Any]) -> tuple[torch.Tensor, dict]:
        """è®­ç»ƒæ—¶çš„åŠ¨ä½œé‡‡æ ·"""
        # 1. è·å–å¹¶å½’ä¸€åŒ–æœ¬ä½“è§‚æµ‹
        proprio_obs = self.get_actor_obs(obs)
        proprio_obs = self.actor_obs_normalizer(proprio_obs)
        
        # 2. æå–é«˜ç¨‹å›¾ç‰¹å¾
        # height_map_sequence = self._extract_height_map_sequence(obs)
        height_map_sequence = obs["height_scan_history"].view(obs["height_scan_history"].shape[0], -1)
        vision_features = self.elevation_net(height_map_sequence)
        
        # 3. èåˆæœ¬ä½“è§‚æµ‹å’Œè§†è§‰ç‰¹å¾å¹¶è¾“å‡ºåŠ¨ä½œ
        fused_features = torch.cat([proprio_obs, vision_features], dim=-1)
        mean = self.fusion_actor(fused_features)
        
        self._update_distribution(mean)
        return self.distribution.sample(), self.extra_info

    def act_inference(self, obs: TensorDict) -> tuple[torch.Tensor, dict]:
        """æ¨ç†æ—¶çš„ç¡®å®šæ€§åŠ¨ä½œ"""
        # 1. è·å–å¹¶å½’ä¸€åŒ–æœ¬ä½“è§‚æµ‹
        proprio_obs = self.get_actor_obs(obs)
        proprio_obs = self.actor_obs_normalizer(proprio_obs)
        
        # 2. æå–é«˜ç¨‹å›¾ç‰¹å¾
        # height_map_sequence = self._extract_height_map_sequence(obs)
        height_map_sequence = obs["height_scan_history"].view(obs["height_scan_history"].shape[0], -1)
        vision_features = self.elevation_net(height_map_sequence)
        
        # 3. èåˆæœ¬ä½“è§‚æµ‹å’Œè§†è§‰ç‰¹å¾å¹¶è¾“å‡ºåŠ¨ä½œï¼ˆç¡®å®šæ€§ï¼‰
        fused_features = torch.cat([proprio_obs, vision_features], dim=-1)
        mean = self.fusion_actor(fused_features)
        
        return mean, self.extra_info

    def evaluate(self, obs: TensorDict, **kwargs: dict[str, Any]) -> torch.Tensor:
        """è¯„ä¼°çŠ¶æ€ä»·å€¼"""
        obs = self.get_critic_obs(obs)
        obs = self.critic_obs_normalizer(obs)
        return self.critic(obs)

    def get_actor_obs(self, obs: TensorDict) -> torch.Tensor:
        """è·å–actorçš„æœ¬ä½“è§‚æµ‹(æ’é™¤é«˜ç¨‹å›¾)"""
        obs_list = []
        for obs_group in self.obs_groups["policy"]:
            if obs_group != "height_scan_history":
                obs_list.append(obs[obs_group])
        return torch.cat(obs_list, dim=-1) if obs_list else torch.empty(obs[self.obs_groups["policy"][0]].shape[0], 0)

    def get_critic_obs(self, obs: TensorDict) -> torch.Tensor:
        """è·å–criticè§‚æµ‹(æ’é™¤é«˜ç¨‹å›¾)"""
        obs_list = []
        for obs_group in self.obs_groups["critic"]:
            if obs_group != "height_scan_history":
                obs_list.append(obs[obs_group])
        return torch.cat(obs_list, dim=-1) if obs_list else torch.empty(obs[self.obs_groups["critic"][0]].shape[0], 0)

    def get_actions_log_prob(self, actions: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—åŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡"""
        return self.distribution.log_prob(actions).sum(dim=-1)

    def update_normalization(self, obs: TensorDict) -> None:
        """æ›´æ–°è§‚æµ‹å½’ä¸€åŒ–ç»Ÿè®¡é‡"""
        if self.actor_obs_normalization:
            actor_obs = self.get_actor_obs(obs)
            self.actor_obs_normalizer.update(actor_obs)
        if self.critic_obs_normalization:
            critic_obs = self.get_critic_obs(obs)
            self.critic_obs_normalizer.update(critic_obs)

    def load_state_dict(self, state_dict: dict, strict: bool = True) -> bool:
        """åŠ è½½æ¨¡å‹å‚æ•°"""
        super().load_state_dict(state_dict, strict=strict)
        return True

    def create_optimizers(self, learning_rate: float) -> dict[str, torch.optim.Optimizer]:
        """åˆ›å»ºä¼˜åŒ–å™¨
        
        Args:
            learning_rate: å­¦ä¹ ç‡
            
        Returns:
            ä¼˜åŒ–å™¨å­—å…¸ï¼ŒåŒ…å«ä¸»è¦çš„ä¼˜åŒ–å™¨
        """
        import torch.optim as optim
        
        optimizer = optim.Adam([
            {'params': self.elevation_net.parameters()},
            {'params': self.fusion_actor.parameters()},
            {'params': self.critic.parameters()},
            {'params': [self.std] if self.noise_std_type == "scalar" else [self.log_std]},
        ], lr=learning_rate)
        
        return {
            "optimizer": optimizer
        }

    def export_to_onnx(self, path: str, filename: str = "ElevationNet_mode2A_policy.onnx", normalizer: torch.nn.Module | None = None, verbose: bool = False) -> None:
        """å°†ElevationNet Mode2Aç­–ç•¥å¯¼å‡ºä¸ºONNXæ ¼å¼
        
        Args:
            path: ä¿å­˜ç›®å½•çš„è·¯å¾„
            filename: å¯¼å‡ºçš„ONNXæ–‡ä»¶åï¼Œé»˜è®¤ä¸º"ElevationNet_mode2A_policy.onnx"
            normalizer: å½’ä¸€åŒ–æ¨¡å—ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨Identity
            verbose: æ˜¯å¦æ‰“å°æ¨¡å‹æ‘˜è¦ï¼Œé»˜è®¤ä¸ºFalse
        """
        import copy
        import os
        
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)
            
        # åˆ›å»ºElevationNet Mode2Aä¸“ç”¨çš„å¯¼å‡ºå™¨
        exporter = _ElevationNetMode2AOnnxPolicyExporter(self, normalizer, verbose)
        exporter.export(path, filename)


class _ElevationNetMode2AOnnxPolicyExporter(torch.nn.Module):
    """ElevationNet Mode2Aç­–ç•¥çš„ONNXå¯¼å‡ºå™¨"""

    def __init__(self, policy: ActorCriticElevationNetMode2A, normalizer=None, verbose=False):
        super().__init__()
        self.verbose = verbose
        # å¤åˆ¶ç­–ç•¥å‚æ•°
        if hasattr(policy, "elevation_net"):
            self.elevation_net = copy.deepcopy(policy.elevation_net)
        if hasattr(policy, "fusion_actor"):
            self.fusion_actor = copy.deepcopy(policy.fusion_actor)

        # å¤åˆ¶å½’ä¸€åŒ–å™¨
        if normalizer:
            self.normalizer = copy.deepcopy(normalizer)
        else:
            self.normalizer = torch.nn.Identity()

    def forward(self, x):
        # å‡è®¾è¾“å…¥æ˜¯ [æœ¬ä½“è§‚æµ‹ + é«˜ç¨‹å›¾åºåˆ—å±•å¹³]
        # éœ€è¦åˆ†ç¦»æœ¬ä½“è§‚æµ‹å’Œé«˜ç¨‹å›¾
        obs_len = self.normalizer.in_features
        proprio_obs = x[:, 0:obs_len]
        height_map_sequence = x[:, obs_len:]
        
        # å½’ä¸€åŒ–æœ¬ä½“è§‚æµ‹
        normalized_obs = self.normalizer(proprio_obs)
        
        # æå–é«˜ç¨‹å›¾ç‰¹å¾
        vision_features = self.elevation_net(height_map_sequence)
        
        # èåˆæœ¬ä½“è§‚æµ‹å’Œè§†è§‰ç‰¹å¾å¹¶è¾“å‡ºåŠ¨ä½œ
        fused_features = torch.cat([normalized_obs, vision_features], dim=-1)
        actions_mean = self.fusion_actor(fused_features)
        return actions_mean

    def export(self, path, filename):
        self.to("cpu")
        self.eval()
        opset_version = 18
        # åˆ›å»ºè¾“å…¥ç¤ºä¾‹
        total_dim = self.normalizer.in_features + self.elevation_net[0].in_features
        obs = torch.zeros(1, total_dim)
        torch.onnx.export(
            self,
            obs,
            os.path.join(path, filename),
            export_params=True,
            opset_version=opset_version,
            verbose=self.verbose,
            input_names=["obs"],
            output_names=["actions"],
            dynamic_axes={},
        )
